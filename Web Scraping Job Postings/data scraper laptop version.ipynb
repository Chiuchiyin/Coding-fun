{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1e0f3f",
   "metadata": {},
   "source": [
    "Cleaner version of the notebook that I run on laptop to scape data faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f9c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from time import time, sleep\n",
    "import random\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af514825",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'jobs1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a84b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file not found, creating new file\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    df_more = pd.read_csv(file , sep='\\t', encoding='utf-8', index_col=0)\n",
    "    print('file successfully opened')\n",
    "except:\n",
    "    print('file not found, creating new file')\n",
    "    df_more = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    df_more.to_csv(file, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832f0a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Location, Company, Salary, Synopsis]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d8f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_list = [\n",
    "# Firefox 77 Mac\n",
    "{\n",
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"DNT\": \"1\",\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\"\n",
    "},\n",
    "# Firefox 77 Windows\n",
    "{\n",
    "\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"DNT\": \"1\",\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\"\n",
    "},\n",
    "# Chrome 83 Mac\n",
    "{\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"DNT\": \"1\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\",\n",
    "\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "\"Sec-Fetch-Site\": \"none\",\n",
    "\"Sec-Fetch-Mode\": \"navigate\",\n",
    "\"Sec-Fetch-Dest\": \"document\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\"\n",
    "},\n",
    "# Chrome 83 Windows \n",
    "{\n",
    "\"Connection\": \"keep-alive\",\n",
    "\"Upgrade-Insecure-Requests\": \"1\",\n",
    "\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "\"Sec-Fetch-Site\": \"same-origin\",\n",
    "\"Sec-Fetch-Mode\": \"navigate\",\n",
    "\"Sec-Fetch-User\": \"?1\",\n",
    "\"Sec-Fetch-Dest\": \"document\",\n",
    "\"Referer\": \"https://www.google.com/\",\n",
    "\"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "\"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91740438",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b061abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10558, 5) data saved, last visited city is  Chicago , continuing....\n",
      "706 loops done, proceed to sleep, current city is  Chicago\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "count = 0\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "                 'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "                 'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        url = url_template.format(city, start)\n",
    "        headers = random.choice(headers_list)\n",
    "        r = requests.Session()\n",
    "        r.headers = headers\n",
    "        html = r.get(url)\n",
    "        #html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        #captcha detector\n",
    "        if 'hCaptcha solve page' in soup.get_text():\n",
    "            print('captcha detected')\n",
    "            winsound.Beep(freq, duration) #sound alert, might get irritating, probably won't work on mac\n",
    "            input(\"Press Enter to continue...\")#this would pause the code until i press enter\n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobTitle').text.replace('\\n', '').replace('new', '')\n",
    "            except:\n",
    "                title = 'None'\n",
    "            try:\n",
    "                location = each.find('div', {'class':\"companyLocation\" }).text.replace('\\n', '')\n",
    "            except:\n",
    "                location = 'None'\n",
    "            try: \n",
    "                company = each.find(class_='companyName').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = 'None'\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'estimated-salary'}).text.replace('\\n', '').replace('Estimated', '')\n",
    "            except:\n",
    "                salary = 'None'\n",
    "            synopsis = each.find('div', {'class':'job-snippet'}).text.replace('\\n', '')\n",
    "            df_more = df_more.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print('You have ' + str(i) + ' results. ' + str(df_more.dropna().drop_duplicates().shape[0]) + \" of these aren't rubbish.\")\n",
    "        #count the number of pages scraped and print, so I know how far the code is running\n",
    "        count+= 1\n",
    "        print(count, 'loops done, proceed to sleep, current city is ', city)\n",
    "        df_more.to_csv(file, sep='\\t', encoding='utf-8')#write every page so i don't lose my data again\n",
    "        sleep(random.randint(7,20))\n",
    "        #I don't want too see long line of the process, clear_output will clear previous lines\n",
    "        clear_output(wait=True)\n",
    "        print(df_more.shape, 'data saved, last visited city is ', city, ', continuing....')\n",
    "    print('moving to next city')\n",
    "    sleep(random.randint(30,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c2c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
