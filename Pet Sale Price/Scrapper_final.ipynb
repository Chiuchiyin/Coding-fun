{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0176e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from time import time, sleep\n",
    "import random\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import visibility_of_element_located\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946d5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = \"https://www.pets4homes.co.uk/{}/{}/local/{}/\"\n",
    "url_template_pages = \"https://www.pets4homes.co.uk/{}/{}/local/{}/page-{}/\"\n",
    "listing_type = ['sale','adoption','stud']\n",
    "pet_type = ['dogs','cats','reptiles','rodents','rabbits','horses','invertebrates','livestock', 'poultry', 'birds','fish']\n",
    "cities = ['aberdeen','ayr_st-ives', 'barnsley_wimborne','basingstoke','bath','bedfordshire','birmingham','blackpool_plymouth',\n",
    "         'bolton_appleby-in-westmorland', 'bournemouth', 'bradford_holsworthy', 'bridgend_brechin', 'brighton',\n",
    "          'bristol_south-west-england', 'cambridge_gloucester', 'cardiff-county', 'carlisle', 'chelmsford', 'cheltenham',\n",
    "         'chester', 'chesterfield', 'colchester', 'cornwall', 'coventry', 'crawley_witney', 'crewe', 'darlington', 'derby', \n",
    "         'devon', 'doncaster', 'dorset', 'dudley_cramlington', 'dundee', 'durham', 'eastbourne', 'edinburgh', 'essex', 'exeter',\n",
    "         'glasgow', 'gloucester', 'grimsby', 'guildford', 'hampshire', 'hereford', 'hertfordshire', 'huddersfield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa4fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_captcha (soup):\n",
    "    if 'I am human' in soup.get_text():\n",
    "            print('captcha detected')\n",
    "            duration = 5000  # milliseconds\n",
    "            freq = 440  # Hz\n",
    "            winsound.Beep(freq, duration) #sound alert, might get irritating, probably won't work on mac\n",
    "            input(\"Press Enter to continue...\")#this would pause the code until i press enter\n",
    "    else:\n",
    "        print('no captcha detected, proceed to scrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01441d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_header(soup):\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Description\",\"photo_link\",\"category\", \"price\", \"url\",\n",
    "                                              \"seller_type\", \"seller_name\", 'listing_type','pet_type'])\n",
    "    for each in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "        entries = each.get_text()\n",
    "        split = entries.split(\"\\n\")\n",
    "        Title = split[3].replace('\"name\": \"', '').replace('\",', '')\n",
    "        Description = split[4].replace('\"description\": \"', '').replace('\",', '').replace('\\n,', '')\n",
    "        Photo = split[5].replace('\"image\": \"', '').replace('\",', '')\n",
    "        Category = split[7].replace('\"category\": \"', '').replace('\",', '')\n",
    "        Price = split[11].replace('\"price\": \"', '').replace('\",', '')\n",
    "        url =split[13].replace('\"url\": \"', '').replace('\",', '')\n",
    "        seller_type = split[15].replace('\"type\": \"', '').replace('\",', '')\n",
    "        seller_name = split[16].replace('\"name\":  \"', '').replace('\"', '')\n",
    "        df = df.append({\"Title\":Title,\"Description\":Description,\"photo_link\":Photo,\"category\":Category, \n",
    "                                      \"price\":Price,\"url\":url, \"seller_type\":seller_type, \"seller_name\":seller_name,\n",
    "                                      \"listing_type\":listing, \"pet_type\": pets},ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce16a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_content(soup):\n",
    "    df1 = pd.DataFrame(columns=[\"Title\",\"price\",\"species\", \"age\", \"gender\", \"description\",\n",
    "                                \"seller_name\", \"seller_location\", \"seller_type\", \"listing_type\",\"pet_type\"])\n",
    "    for each in soup.find_all(\"div\", class_=\"mn aj\"):\n",
    "        entries = each.get_text()\n",
    "        title = each.find('h2', {'class':'wn'}).text\n",
    "        price = each.find('span', {'class':'xn'}).text\n",
    "        info = each.find_all('span', {'class':'rv'})\n",
    "        species = info[0].text\n",
    "        try:\n",
    "            age = info[1].text.replace('Age:  ', '')\n",
    "        except:\n",
    "            age = 'unknown'\n",
    "        try:\n",
    "            gender = info[2].text\n",
    "        except:\n",
    "            gender = 'unknown'\n",
    "        description = each.find('span', {'class':'yn'}).text\n",
    "        seller_name = each.find('span', {'class':'En'}).text\n",
    "        seller_location = each.find('span', {'class':'Ct'}).text\n",
    "        seller_type = each.find('div', {'class':'se sm te'}).text\n",
    "        df1 = df1.append({\"Title\":title, \"price\":price, \"species\":species, \"age\":age, \"gender\":gender,\n",
    "                              \"description\":description, \"seller_name\":seller_name, \"seller_location\": seller_location,\n",
    "                              \"seller_type\":seller_type, \"listing_type\":listing, \"pet_type\": pets},ignore_index=True)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b0bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen fish sale 2\n",
      "no captcha detected, proceed to scrape\n",
      "no new data\n",
      "going to next listing type\n",
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen fish adoption 1\n",
      "no captcha detected, proceed to scrape\n",
      "no result found\n",
      "going to next listing type\n",
      "going to next pet type\n",
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen livestock stud 1\n",
      "no captcha detected, proceed to scrape\n",
      "no result found\n",
      "going to next listing type\n",
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen livestock sale 1\n",
      "no captcha detected, proceed to scrape\n",
      "no result found\n",
      "going to next listing type\n",
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen livestock adoption 1\n",
      "no captcha detected, proceed to scrape\n",
      "no result found\n",
      "going to next listing type\n",
      "going to next pet type\n",
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen horses stud 1\n",
      "no captcha detected, proceed to scrape\n",
      "no result found\n",
      "going to next listing type\n",
      "file successfully opened\n",
      "file successfully opened\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\silve\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberdeen horses sale 1\n",
      "no captcha detected, proceed to scrape\n",
      "no result found\n"
     ]
    }
   ],
   "source": [
    "for city in set (cities):\n",
    "    for pets in set(pet_type):\n",
    "        for listing in set(listing_type):\n",
    "            page = 1\n",
    "            while page > 0:\n",
    "                clear_output(wait=True)\n",
    "                file = 'data_by_cities/header_'+str(city)+'.csv'\n",
    "                file1 = 'data_by_cities/body_'+str(city)+'.csv'\n",
    "                try: \n",
    "                    df_header = pd.read_csv(file , sep='\\t', encoding='utf-8', index_col=0)\n",
    "                    print('file successfully opened')\n",
    "                except:\n",
    "                    print('file not found, creating new file')\n",
    "                    df_header = pd.DataFrame(columns=[\"Title\",\"Description\",\"photo_link\",\"category\", \"price\", \"url\",\n",
    "                                              \"seller_type\", \"seller_name\", 'listing_type','pet_type'])\n",
    "                    df_header.to_csv(file, sep='\\t', encoding='utf-8')\n",
    "                try: \n",
    "                    df_body = pd.read_csv(file1 , sep='\\t', encoding='utf-8', index_col=0)\n",
    "                    print('file successfully opened')\n",
    "                except:\n",
    "                    print('file not found, creating new file')\n",
    "                    df_body = pd.DataFrame(columns=[\"Title\",\"price\",\"species\", \"age\", \"gender\", \"description\",\n",
    "                                                    \"seller_name\", \"seller_location\", \"seller_type\" , \n",
    "                                                    \"listing_type\",\"pet_type\"])\n",
    "                    df_body.to_csv(file1, sep='\\t', encoding='utf-8')\n",
    "                headersize = df_header.shape\n",
    "                bodysize = df_body.shape\n",
    "                if page == 1:\n",
    "                    url = url_template.format(listing, pets, city)\n",
    "                else:\n",
    "                    url = url_template_pages.format(listing, pets, city, page)\n",
    "                options = webdriver.ChromeOptions()\n",
    "                browser = webdriver.Chrome(ChromeDriverManager().install(),options = options)\n",
    "                browser.get(url)\n",
    "                title = (\n",
    "                    WebDriverWait(driver=browser, timeout=10)\n",
    "                    .until(visibility_of_element_located((By.CSS_SELECTOR, \"h1\"))).text\n",
    "                )\n",
    "                content = browser.page_source\n",
    "                print(city,pets,listing,page)\n",
    "                soup = BeautifulSoup(content, 'lxml')\n",
    "                check_captcha(soup)\n",
    "                if 'We found 0' in soup.get_text():\n",
    "                    print('no result found')\n",
    "                    break\n",
    "                df_header = df_header.append(scrape_header(soup))\n",
    "                df_body = df_body.append(scrape_content(soup))\n",
    "                #drop duplicates\n",
    "                df_header = df_header[~df_header.duplicated()].reset_index(drop=True)\n",
    "                df_header.to_csv(file, sep='\\t', encoding='utf-8')\n",
    "                df_body = df_body[~df_body.duplicated()].reset_index(drop=True)\n",
    "                df_body.to_csv(file1, sep='\\t', encoding='utf-8')\n",
    "                if df_body.shape == bodysize:\n",
    "                    if df_header.shape == headersize:\n",
    "                        print('no new data')\n",
    "                        break\n",
    "                    else:\n",
    "                        winsound.Beep(600, 1000)\n",
    "                        input('html tags changed, please kill program')\n",
    "                sleep(random.randint(10,15))\n",
    "                print('going to next page')\n",
    "                page +=1\n",
    "            sleep(random.randint(10,15))\n",
    "            print('going to next listing type')\n",
    "        sleep(random.randint(10,15))\n",
    "        print('going to next pet type')\n",
    "    sleep(random.randint(15,20))\n",
    "    print('going to next city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d845ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd1d808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodysize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c783928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_body.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1ff23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_header.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2508e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
